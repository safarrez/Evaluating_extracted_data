{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F8hCd9Wc4dn"
      },
      "source": [
        "##  Creating the DB\n",
        "This document is solely for testing localy, i am not sure if it can be applied to the current code but i will try my best to make it as compatible as possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlite3 \n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \"Pre processing\" the data \n",
        "it would be great to have the file path with it in each data frame\n",
        "(this is nearly identical to what Anna is doing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in c:\\users\\farah\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\farah\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openpyxl) (2.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\farah\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Study_ID</th>\n",
              "      <th>Study</th>\n",
              "      <th>Allocation</th>\n",
              "      <th>Experimenter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Chacko et al 2017</td>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Chacko et al 2017</td>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Coyne et al 2004</td>\n",
              "      <td>Non-random</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Coyne et al 2004</td>\n",
              "      <td>Non-random</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Purpura et al 2017</td>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>54</td>\n",
              "      <td>Hassinger-Das (2013)</td>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>54</td>\n",
              "      <td>Hassinger-Das (2013)</td>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>54</td>\n",
              "      <td>Hassinger-Das (2013)</td>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>27</td>\n",
              "      <td>Crandell 2010</td>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>27</td>\n",
              "      <td>Crandell 2010</td>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>316 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Study_ID                 Study  Allocation Experimenter\n",
              "0           1     Chacko et al 2017      Random       Parent\n",
              "1           1     Chacko et al 2017      Random       Parent\n",
              "2           2      Coyne et al 2004  Non-random      Teacher\n",
              "3           2      Coyne et al 2004  Non-random      Teacher\n",
              "4           3    Purpura et al 2017      Random   Researcher\n",
              "..        ...                   ...         ...          ...\n",
              "311        54  Hassinger-Das (2013)      Random   Researcher\n",
              "312        54  Hassinger-Das (2013)      Random   Researcher\n",
              "313        54  Hassinger-Das (2013)      Random   Researcher\n",
              "314        27         Crandell 2010      Random      Teacher\n",
              "315        27         Crandell 2010      Random      Teacher\n",
              "\n",
              "[316 rows x 4 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_excel('content\\ground_truth\\data.xlsx')\n",
        "ground_truth_df = df[['Study_ID', 'Study', 'Allocation', 'Experimenter']]\n",
        "ground_truth_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Bianco et al. - 2010 - Early Training in Oral Comprehension and Phonological Skills Results of a Three-Year Longitudinal S.pdf.csv\n",
            "Loaded Blom-Hoffman et al. - 2007 - Instructing Parents to Use Dialogic Reading Strategies with Preschool Children Impact of a Video-Ba.pdf.csv\n",
            "Loaded Carson - 2012 - Read with Me! Examining the Effects of a Community Volunteer Reading Program on Preschoolers' Litera.pdf.csv\n",
            "Loaded Coyne et al. - 2004 - Teaching Vocabulary During Shared Storybook Readings An Examination of Differential Effects.pdf.csv\n",
            "Loaded Coyne et al. - 2010 - Direct and Extended Vocabulary Instruction in Kindergarten Investigating Transfer Effects.pdf.csv\n",
            "Loaded Crain-Thoreson and Dale - 1999 - Enhancing Linguistic Performance Parents and Teachers as Book Reading Partners for Children with La.pdf.csv\n",
            "Loaded Crandell - 2010 - Information book read-alouds in Head Start preschools and the development of preschoolers' vocabular.pdf.csv\n",
            "Loaded Herrell - 1989 - A child and an adult interact with a book The effects on language and literacy in kindergarten.pdf.csv\n",
            "Loaded Korat and Shamir - 2007 - Electronic books versus adult readers effects on children's emergent literacy as a function of soci.pdf.csv\n",
            "Loaded Korat et al. - 2013 - Expanding the boundaries of shared book reading E-books and printed books in parent–child reading a.pdf.csv\n",
            "Loaded Lefebvre et al. - 2011 - Enhancing vocabulary, print awareness and phonological awareness through shared storybook reading wi.pdf.csv\n",
            "Loaded Lever and Sénéchal - 2011 - Discussing stories On how a dialogic reading intervention improves kindergartners’ oral narrative c.pdf.csv\n",
            "Loaded Lever and Sénéchal - 2011 - Discussing stories On how a dialogic reading intervention improves kindergartners’ oral narrative c.pdf.csv\n",
            "Loaded Neuman - 1999 - Books Make a Difference A Study of Access to Literacy.pdf.csv\n",
            "Loaded Wing-Yin Chow and McBride-Chang - 2003 - Promoting Language and Literacy Development through Parent–Child Reading in Hong Kong Preschoolers.pdf.csv\n",
            "Loaded Woods - 2017 - Interactive Book Reading Promoting Emergent Literacy Skills in Preschool Children through a Parent.pdf.csv\n",
            "Loaded Yeh and Connell - 2008 - Effects of rhyming, vocabulary and phonemic awareness instruction on phoneme awareness.pdf.csv\n",
            "Combined DataFrame created.\n"
          ]
        }
      ],
      "source": [
        "# extracting data from the csv files in the extracted directory\n",
        "\n",
        "extracted_dir = 'content\\extracted_split_2_shuffle_2'\n",
        "extracted_dfs = []\n",
        "\n",
        "if os.path.exists(extracted_dir):\n",
        "    for filename in os.listdir(extracted_dir):\n",
        "        if filename.endswith('.csv'):\n",
        "            file_path = os.path.join(extracted_dir, filename)\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "                extracted_dfs.append(df)\n",
        "                print(f\"Loaded {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {filename}: {e}\")\n",
        "\n",
        "if extracted_dfs:\n",
        "    extracted_combined_df = pd.concat(extracted_dfs, ignore_index=True)\n",
        "    print(\"Combined DataFrame created.\")\n",
        "else:\n",
        "    print(\"No CSV files found in the directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# directly taken from Anna's code\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
        "\n",
        "def format_studyName(study_name_string):\n",
        "    \"\"\"\n",
        "    Cuts a string after the last four-digit number, assuming it represents the year.\n",
        "\n",
        "    Args:\n",
        "        study_name_string (str): The input string potentially containing a year.\n",
        "\n",
        "    Returns:\n",
        "        str: The string cut after the year, or the original string if no year is found.\n",
        "    \"\"\"\n",
        "    # Get rid of all the points, -\n",
        "    study_name_string = study_name_string.replace('.', '')\n",
        "    study_name_string = study_name_string.replace(',', '')\n",
        "    study_name_string = study_name_string.replace(' - ', ' ')\n",
        "    study_name_string = study_name_string.replace(')', '')\n",
        "    study_name_string = study_name_string.replace('(', '')\n",
        "    study_name_string = study_name_string.replace('&', 'and')\n",
        "    study_name_string = remove_accents(study_name_string)\n",
        "    # Find all occurrences of four consecutive digits (potential years)\n",
        "    year_matches = list(re.finditer(r'\\b\\d{4}\\b', study_name_string))\n",
        "\n",
        "    if year_matches:\n",
        "        # Get the last match\n",
        "        last_year_match = year_matches[-1]\n",
        "        # Get the end index of the last year match\n",
        "        end_of_year_index = last_year_match.end()\n",
        "        # Slice the string up to the end of the year\n",
        "        cut_string = study_name_string[:end_of_year_index]\n",
        "        return cut_string.strip() # Use strip to remove trailing whitespace\n",
        "    else:\n",
        "        # If no four-digit number is found, return the original string\n",
        "        return study_name_string.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Allocation</th>\n",
              "      <th>Experimenter</th>\n",
              "      <th>Study</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Bianco et al 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Blom-Hoffman et al 2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Carson 2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Coyne et al 2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Coyne et al 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Crain-Thoreson and Dale 1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Crandell 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Herrell 1989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Korat and Shamir 2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Korat et al 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Lefebvre et al 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Lever and Senechal 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Lever and Senechal 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Neuman 1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Wing-Yin Chow and McBride-Chang 2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Woods 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Yeh and Connell 2008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Allocation Experimenter                                 Study\n",
              "0      Random       Parent                     Bianco et al 2010\n",
              "1      Random       Parent               Blom-Hoffman et al 2007\n",
              "2      Random       Parent                           Carson 2012\n",
              "3      Random       Parent                      Coyne et al 2004\n",
              "4      Random       Parent                      Coyne et al 2010\n",
              "5      Random       Parent          Crain-Thoreson and Dale 1999\n",
              "6      Random       Parent                         Crandell 2010\n",
              "7      Random       Parent                          Herrell 1989\n",
              "8      Random       Parent                 Korat and Shamir 2007\n",
              "9      Random       Parent                      Korat et al 2013\n",
              "10     Random       Parent                   Lefebvre et al 2011\n",
              "11     Random       Parent               Lever and Senechal 2011\n",
              "12     Random       Parent               Lever and Senechal 2011\n",
              "13     Random       Parent                           Neuman 1999\n",
              "14     Random       Parent  Wing-Yin Chow and McBride-Chang 2003\n",
              "15     Random       Parent                            Woods 2017\n",
              "16     Random       Parent                  Yeh and Connell 2008"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extracted_combined_df['Study'] = extracted_combined_df['Study'].apply(format_studyName)\n",
        "extracted_combined_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the dataBase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "INQswD0YsqXt"
      },
      "outputs": [],
      "source": [
        "def creatingDB(gt, extracted, table_nameGt, table_name_extracted):\n",
        "  '''creates a SQLite database with the same structure as the given DataFrame and inserts the data into it.\n",
        "  Args:\n",
        "      gt (DataFrame): The ground truth DataFrame.\n",
        "      extracted (DataFrame): The extracted DataFrame.\n",
        "      table_nameGt (str): The name of the table for ground truth data.\n",
        "      table_name_extracted (str): The name of the table for extracted data.\n",
        "  '''\n",
        "  \n",
        "  # Connect to database\n",
        "  conn = sqlite3.connect('content/database.db')\n",
        "\n",
        "  # Dropping the tables if they exist\n",
        "  conn.execute(f\"DROP TABLE IF EXISTS {table_nameGt}\")\n",
        "  conn.execute(f\"DROP TABLE IF EXISTS {table_name_extracted}\")\n",
        "\n",
        "  # Automatically create table with same name and structure\n",
        "  gt.to_sql(table_nameGt, conn, if_exists='append', index=False)\n",
        "  extracted.to_sql(table_name_extracted, conn, if_exists='append', index=False)\n",
        "\n",
        "  print(\"Tables created with the same structure as the CSV and data inserted.\")\n",
        "  \n",
        "  # Done\n",
        "  conn.commit()\n",
        "  conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables created with the same structure as the CSV and data inserted.\n"
          ]
        }
      ],
      "source": [
        "gt_table = 'Ground_truth'\n",
        "extracted_table = 'Extracted'\n",
        "creatingDB(ground_truth_df, extracted_combined_df, gt_table, extracted_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculating the mesures\n",
        "Auxilary functions used to calculate the mesures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculateAccuracy(TP, FP, FN):\n",
        "    '''calculates the accuracy of a model based on true positives, true negatives, false positives, and false negatives.'''\n",
        "    return TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
        "\n",
        "def calculatePrecision(TP, FP):\n",
        "    '''calculates the precision of a model based on true positives and false positives.'''\n",
        "    return TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "\n",
        "def calculateRecall(TP, FN):\n",
        "    '''calculates the recall of a model based on true positives and false negatives.'''\n",
        "    return TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "def calculateF1Score(precision, recall):\n",
        "    '''calculates the F1 score based on precision and recall.'''\n",
        "    return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "def calculateMetrics(TP, FP, FN):\n",
        "    '''calculates various metrics based on true positives, false positives, and false negatives.'''\n",
        "    # --- Metrics ---\n",
        "    accuracy = calculateAccuracy(TP, FP, FN) \n",
        "    recall = calculateRecall(TP, FN)\n",
        "    precision = calculatePrecision(TP, FP)\n",
        "    f1 = calculateF1Score(precision, recall)\n",
        "\n",
        "    return {\n",
        "        'Accuracy': round(accuracy, 4),\n",
        "        'Recall': round(recall, 4),\n",
        "        'Precision': round(precision, 4),\n",
        "        'F1': round(f1, 4)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SQL queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground Truth Table count:\n",
            "(316,)\n",
            "\n",
            "Extracted Table count:\n",
            "(17,)\n",
            "Total matched rows: 31\n",
            "Ground Truth Table:\n",
            "(1, 'Chacko et al 2017', 'Random', 'Parent')\n",
            "(1, 'Chacko et al 2017', 'Random', 'Parent')\n",
            "(2, 'Coyne et al 2004', 'Non-random', 'Teacher')\n",
            "(2, 'Coyne et al 2004', 'Non-random', 'Teacher')\n",
            "(3, 'Purpura et al 2017', 'Random', 'Researcher')\n",
            "(3, 'Purpura et al 2017', 'Random', 'Researcher')\n",
            "(4, 'Vaknin-Nusbau & Nevo 2017', 'Random', 'Teacher')\n",
            "(4, 'Vaknin-Nusbau & Nevo 2017', 'Random', 'Teacher')\n",
            "(4, 'Vaknin-Nusbau & Nevo 2017', 'Random', 'Teacher')\n",
            "(4, 'Vaknin-Nusbau & Nevo 2017', 'Random', 'Teacher')\n",
            "(4, 'Vaknin-Nusbau & Nevo 2017', 'Random', 'Teacher')\n",
            "(4, 'Vaknin-Nusbau & Nevo 2017', 'Random', 'Teacher')\n",
            "(5, 'Wing-Yin Chow & McBride-Chang 2003', 'Random', 'Parent')\n",
            "(5, 'Wing-Yin Chow & McBride-Chang 2003', 'Random', 'Parent')\n",
            "(5, 'Wing-Yin Chow & McBride-Chang 2003', 'Random', 'Parent')\n",
            "\n",
            "Extracted Table:\n",
            "('Random', 'Parent', 'Bianco et al 2010')\n",
            "('Random', 'Parent', 'Blom-Hoffman et al 2007')\n",
            "('Random', 'Parent', 'Carson 2012')\n",
            "('Random', 'Parent', 'Coyne et al 2004')\n",
            "('Random', 'Parent', 'Coyne et al 2010')\n",
            "('Random', 'Parent', 'Crain-Thoreson and Dale 1999')\n",
            "('Random', 'Parent', 'Crandell 2010')\n",
            "('Random', 'Parent', 'Herrell 1989')\n",
            "('Random', 'Parent', 'Korat and Shamir 2007')\n",
            "('Random', 'Parent', 'Korat et al 2013')\n",
            "('Random', 'Parent', 'Lefebvre et al 2011')\n",
            "('Random', 'Parent', 'Lever and Senechal 2011')\n",
            "('Random', 'Parent', 'Lever and Senechal 2011')\n",
            "('Random', 'Parent', 'Neuman 1999')\n",
            "('Random', 'Parent', 'Wing-Yin Chow and McBride-Chang 2003')\n",
            "('Random', 'Parent', 'Woods 2017')\n",
            "('Random', 'Parent', 'Yeh and Connell 2008')\n"
          ]
        }
      ],
      "source": [
        "def printAllTables():\n",
        "    '''affiche toutes les tables de la base de données.'''\n",
        "\n",
        "    conn = sqlite3.connect('content/database.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # testing if the data is inserted correctly\n",
        "    cursor.execute(f\"SELECT * FROM {gt_table} LIMIT 15;\")\n",
        "    print(\"Ground Truth Table:\")\n",
        "    for row in cursor.fetchall():\n",
        "        print(row)\n",
        "\n",
        "    cursor.execute(f\"SELECT * FROM {extracted_table} ;\")\n",
        "    print(\"\\nExtracted Table:\")\n",
        "    for row in cursor.fetchall():\n",
        "        print(row)\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def countElements():\n",
        "    '''counts the number of elements in each table and prints the result.'''\n",
        "\n",
        "    conn = sqlite3.connect('content/database.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # testing if the data is inserted correctly\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {gt_table};\")\n",
        "    print(\"Ground Truth Table count:\")\n",
        "    print(cursor.fetchall()[0])\n",
        "        \n",
        "\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {extracted_table} ;\")\n",
        "    print(\"\\nExtracted Table count:\")\n",
        "    print(cursor.fetchall()[0])\n",
        "\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(ext.Study)\n",
        "        FROM {gt_table} AS gt\n",
        "                JOIN {extracted_table} AS ext ON gt.Study = ext.Study\n",
        "        \"\"\")\n",
        "    print(\"Total matched rows:\", cursor.fetchone()[0])\n",
        "\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "countElements()\n",
        "printAllTables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mesures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mesuring For binary values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def truePositives(conn, gt, extracted, column = 'Allocation', positiveValue = 'Random'):\n",
        "    '''calculates the number of true positives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'Random'\n",
        "\n",
        "        Args:\n",
        "            conn (str): The path to the SQLite database.\n",
        "            gt (str): The name of the ground truth table.\n",
        "            extracted (str): The name of the extracted data table.\n",
        "            column (str): The column to check for the positive value. Default is 'Allocation'.\n",
        "            positiveValue (str): The value to check for in the specified column. Default is 'Random'.\n",
        "        Returns:\n",
        "            int: The count of true positives.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(*) \n",
        "        FROM {gt} AS gt \n",
        "            JOIN {extracted} AS ext ON gt.Study = ext.Study \n",
        "        WHERE gt.{column} = '{positiveValue}' AND ext.{column} = '{positiveValue}'\n",
        "    \"\"\")\n",
        "    result = cursor.fetchone()\n",
        "    TP_count = result[0]\n",
        "    \n",
        "    print(f\"Number of True Positives for '{column}': {TP_count}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return TP_count\n",
        "\n",
        "def falsePositives(conn, gt, extracted, column = 'Allocation', positiveValue = 'Random' ):\n",
        "    '''calculates the number of true positives based on ground truth and extracted data.\n",
        "        where gt = Random (1) and extracted (model output) = Non-random (0)\n",
        "        Args:\n",
        "            conn (str): The path to the SQLite database.\n",
        "            gt (str): The name of the ground truth table.\n",
        "            extracted (str): The name of the extracted data table.\n",
        "            column (str): The column to check for the positive value. Default is 'Allocation'.\n",
        "            positiveValue (str): The value to check for in the specified column. Default is 'Random'.\n",
        "        Returns:\n",
        "            int: The count of false positives.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(*) FROM {gt} AS gt\n",
        "        JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "        WHERE gt.{column} = '{positiveValue}' AND ext.{column} != '{positiveValue}'\n",
        "    \"\"\")\n",
        "    result = cursor.fetchone()\n",
        "    FP_count = result[0]\n",
        "    \n",
        "    print(f\"Number of false Positives for '{column}': {FP_count}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return FP_count\n",
        "\n",
        "def falseNegatives(conn, gt, extracted, column = 'Allocation', positiveValue = 'Random'):\n",
        "    '''calculates the number of true positives based on ground truth and extracted data.\n",
        "        where gt = Non-random (0) and extracted (model output) = Random (1)\n",
        "        Args:\n",
        "            conn (str): The path to the SQLite database.\n",
        "            gt (str): The name of the ground truth table.\n",
        "            extracted (str): The name of the extracted data table.\n",
        "            column (str): The column to check for the positive value. Default is 'Allocation'.\n",
        "            positiveValue (str): The value to check for in the specified column. Default is 'Random'.\n",
        "        Returns:\n",
        "            int: The count of false negatives.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(*) FROM {gt} AS gt\n",
        "        JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "        WHERE gt.{column} != '{positiveValue}' AND ext.{column} = '{positiveValue}'\n",
        "    \"\"\")\n",
        "    result = cursor.fetchone()\n",
        "    FN_count = result[0]\n",
        "    \n",
        "    print(f\"Number of false Negatives for '{column}': {FN_count}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return FN_count\n",
        "\n",
        "def trueNegatives(conn, gt, extracted, column = 'Allocation', positiveValue = 'Random'):\n",
        "    '''calculates the number of true negatives based on ground truth and extracted data.\n",
        "        where gt = Non-random (0) and extracted (model output) = Non-random (0)\n",
        "        Args:\n",
        "            conn (str): The path to the SQLite database.\n",
        "            gt (str): The name of the ground truth table.\n",
        "            extracted (str): The name of the extracted data table.\n",
        "            column (str): The column to check for the positive value. Default is 'Allocation'.\n",
        "            positiveValue (str): The value to check for in the specified column. Default is 'Random'.\n",
        "        Returns:\n",
        "            int: The count of true negatives.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(*) FROM {gt} AS gt\n",
        "        JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "        WHERE gt.{column} != '{positiveValue}' AND ext.{column} != '{positiveValue}'\n",
        "    \"\"\")\n",
        "    result = cursor.fetchone()\n",
        "    TN_count = result[0]\n",
        "    \n",
        "    print(f\"Number of true Negatives for '{column}': {TN_count}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return TN_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of True Positives for 'Allocation': 12\n",
            "Number of false Positives for 'Allocation': 0\n",
            "Number of false Negatives for 'Allocation': 19\n",
            "Number of true Negatives for 'Allocation': 0\n",
            "Calculating metrics... : \n",
            " {'Accuracy': 0.3871, 'Recall': 0.3871, 'Precision': 1.0, 'F1': 0.5581}\n"
          ]
        }
      ],
      "source": [
        "#print(\"True Positives:\")\n",
        "TP = truePositives('content/database.db', gt_table, extracted_table, 'Allocation')\n",
        "\n",
        "#print(\"false Positives:\")\n",
        "FP = falsePositives('content/database.db', gt_table, extracted_table, 'Allocation')\n",
        "\n",
        "#print(\"false Negatives:\")\n",
        "FN = falseNegatives('content/database.db', gt_table, extracted_table, 'Allocation')\n",
        "\n",
        "TN = trueNegatives('content/database.db', gt_table, extracted_table, 'Allocation')\n",
        "\n",
        "print(\"Calculating metrics... : \\n\", calculateMetrics(TP, FP, FN))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi class values \n",
        "Exparimenter\n",
        "Basically it's when the selected column can be more then 2 values (non binary), i think it can work with allocation (binary values) but i still did a separate case for it just in case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def truePositivesExperimenter(conn, gt, extracted, column = 'Experimenter', \n",
        "                              values = ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent']):\n",
        "    \n",
        "    '''calculates the number of true positives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'teacher', 'parent', 'researcher' or 'Combined - Teacher and Parent'\n",
        "    Args:\n",
        "        conn (str): The path to the SQLite database.\n",
        "        gt (str): The name of the ground truth table.\n",
        "        extracted (str): The name of the extracted data table.\n",
        "        column (str): The column to check for the positive value. Default is 'Experimenter'.\n",
        "        values (list): The list of values to check for in the specified column. Default is ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent'].\n",
        "    Returns:\n",
        "        list: A list of counts of true positives for each value in the specified column.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    TP_count = []\n",
        "    for value in values:\n",
        "        cursor.execute(f\"\"\"\n",
        "            SELECT COUNT(*)\n",
        "            FROM {gt} AS gt \n",
        "                JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "            WHERE gt.{column} = '{value}' AND ext.{column} = '{value}'\n",
        "        \"\"\")\n",
        "        result = cursor.fetchone()\n",
        "        for row in result:\n",
        "            print(f\"True Positives for {value}: {row}\")\n",
        "            TP_count.append(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return TP_count\n",
        "\n",
        "def falsePositivesExperimenter(conn, gt, extracted, column = 'Experimenter', \n",
        "                              values = ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent']):\n",
        "    \n",
        "    '''calculates the number of False positives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'teacher', 'parent', 'researcher' or 'Combined - Teacher and Parent'\n",
        "    Args:\n",
        "        conn (str): The path to the SQLite database.\n",
        "        gt (str): The name of the ground truth table.\n",
        "        extracted (str): The name of the extracted data table.\n",
        "        column (str): The column to check for the positive value. Default is 'Experimenter\n",
        "        values (list): The list of values to check for in the specified column. Default is ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent'].\n",
        "    Returns:\n",
        "        list: A list of counts of false positives for each value in the specified column.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    TP_count = []\n",
        "    for value in values:\n",
        "        cursor.execute(f\"\"\"\n",
        "            SELECT COUNT(*)\n",
        "            FROM {gt} AS gt \n",
        "                JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "            WHERE gt.{column} != '{value}' AND ext.{column} = '{value}'\n",
        "        \"\"\")\n",
        "        result = cursor.fetchone()\n",
        "        for row in result:\n",
        "            print(f\"False Positives for {value}: {row}\")\n",
        "            TP_count.append(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return TP_count\n",
        "\n",
        "def falseNegativesExperimenter(conn, gt, extracted, column = 'Experimenter', \n",
        "                              values = ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent']):\n",
        "    \n",
        "    '''calculates the number of False nergatives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'teacher', 'parent', 'researcher' or 'Combined - Teacher and Parent'\n",
        "    Args:\n",
        "        conn (str): The path to the SQLite database.\n",
        "        gt (str): The name of the ground truth table.\n",
        "        extracted (str): The name of the extracted data table.\n",
        "        column (str): The column to check for the positive value. Default is 'Experimenter'.\n",
        "        values (list): The list of values to check for in the specified column. Default is ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent'].\n",
        "    Returns:\n",
        "        list: A list of counts of false negatives for each value in the specified column.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    FN_count = []\n",
        "    for value in values:\n",
        "        cursor.execute(f\"\"\"\n",
        "            SELECT COUNT(*)\n",
        "            FROM {gt} AS gt \n",
        "                JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "            WHERE gt.{column} = '{value}' AND ext.{column} != '{value}'\n",
        "        \"\"\")\n",
        "        result = cursor.fetchone()\n",
        "        for row in result:\n",
        "            print(f\"False negatives for {value}: {row}\")\n",
        "            FN_count.append(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return FN_count\n",
        "\n",
        "def trueNegativesExperimenter(conn, gt, extracted, column = 'Experimenter', \n",
        "                              values = ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent']):\n",
        "    \n",
        "    '''calculates the number of True negatives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'teacher', 'parent', 'researcher' or 'Combined - Teacher and Parent'\n",
        "    Args:\n",
        "        conn (str): The path to the SQLite database.\n",
        "        gt (str): The name of the ground truth table.\n",
        "        extracted (str): The name of the extracted data table.\n",
        "        column (str): The column to check for the positive value. Default is 'Experimenter'.\n",
        "        values (list): The list of values to check for in the specified column. Default is ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent'].\n",
        "    Returns:\n",
        "        list: A list of counts of true negatives for each value in the specified column.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    TN_count = []\n",
        "    for value in values:\n",
        "        cursor.execute(f\"\"\"\n",
        "            SELECT COUNT(*)\n",
        "            FROM {gt} AS gt \n",
        "                JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "            WHERE gt.{column} != '{value}' AND ext.{column} != '{value}'\n",
        "        \"\"\")\n",
        "        result = cursor.fetchone()\n",
        "        for row in result:\n",
        "            print(f\"True Negatives for {value}: {row}\")\n",
        "            TN_count.append(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return TN_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Positives for Teacher: 0\n",
            "True Positives for Parent: 6\n",
            "True Positives for Researcher: 0\n",
            "True Positives for Combined - Teacher and Parent: 0\n",
            "Sum of TPE: 6\n",
            "False Positives for Teacher: 0\n",
            "False Positives for Parent: 24\n",
            "False Positives for Researcher: 0\n",
            "False Positives for Combined - Teacher and Parent: 0\n",
            "Sum of FPE: 24\n",
            "False negatives for Teacher: 22\n",
            "False negatives for Parent: 0\n",
            "False negatives for Researcher: 2\n",
            "False negatives for Combined - Teacher and Parent: 0\n",
            "Sum of FNE: 24\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Accuracy': 0.1111, 'Recall': 0.2, 'Precision': 0.2, 'F1': 0.2}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##### use a function instead to group all this ######\n",
        "\n",
        "TPE = truePositivesExperimenter('content/database.db', gt_table, extracted_table, 'Experimenter') \n",
        "TPE_sum = sum(TPE)\n",
        "print(\"Sum of TPE:\", TPE_sum)\n",
        "\n",
        "FPE = falsePositivesExperimenter('content/database.db', gt_table, extracted_table, 'Experimenter')\n",
        "FPE_sum = sum(FPE)\n",
        "print(\"Sum of FPE:\", FPE_sum)\n",
        "\n",
        "FNE = falseNegativesExperimenter('content/database.db', gt_table, extracted_table, 'Experimenter')\n",
        "FNE_sum = sum(FNE)\n",
        "print(\"Sum of FNE:\", FNE_sum)\n",
        "\n",
        "calculateMetrics(TPE_sum, FPE_sum, FNE_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#provided by Anna \n",
        "def accuracy_check(col_name, df_extracted, test_table):\n",
        "  allocation_match = False\n",
        "  experimenter_match = False\n",
        "\n",
        "  # Check if both dataframes have the expected columns and rows\n",
        "  if col_name in df_extracted.columns and \\\n",
        "    not df_extracted.empty and not test_table.empty:\n",
        "\n",
        "      extracted_allocation = df_extracted[col_name].iloc[0]\n",
        "\n",
        "      ground_truth_allocation = test_table[col_name].iloc[0]\n",
        "\n",
        "      # Simple case-insensitive comparison\n",
        "      if str(extracted_allocation).lower() == str(ground_truth_allocation).lower():\n",
        "          allocation_match = True\n",
        "          print(f'{col_name}: Match')\n",
        "      else:\n",
        "          print(f\"{col_name}: Mismatch (Extracted: '{extracted_allocation}', Ground Truth: '{ground_truth_allocation}')\")\n",
        "  else:\n",
        "    print(\"Cannot perform accuracy check: Extracted or ground truth data is missing or malformed.\")\n",
        "  print(\"--------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Useful queries \n",
        "i'm just testing things out i don't really know what they want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def idkWhatToFind(conn, gt, ext):\n",
        "    '''. Distribution of Experimenter Types by Allocation\n",
        "        Sees how Experimenter types are distributed for each Allocation value in ground truth:\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(f\"\"\"\n",
        "                    SELECT Allocation, Experimenter, COUNT(*) AS Count\n",
        "                    FROM {gt}\n",
        "                    GROUP BY Allocation, Experimenter\n",
        "                    ORDER BY Allocation, Count DESC; \"\"\")\n",
        "    test_table = cursor.fetchall()\n",
        "    print(\"Distribution of Experimenter Types by Allocation\")\n",
        "    print(\"in the ground truth table:\")\n",
        "    for row in test_table:\n",
        "        print(row)\n",
        "    \n",
        "    cursor.execute(f\"\"\"\n",
        "                    SELECT Allocation, Experimenter, COUNT(*) AS Count\n",
        "                    FROM {ext}\n",
        "                    GROUP BY Allocation, Experimenter\n",
        "                    ORDER BY Allocation, Count DESC; \"\"\")\n",
        "    test_table = cursor.fetchall()\n",
        "    print(\"in the extracted table:\")\n",
        "    for row in test_table:\n",
        "        print(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribution of Experimenter Types by Allocation\n",
            "in the ground truth table:\n",
            "('Non-random', 'Teacher', 30)\n",
            "('Non-random', 'Researcher', 11)\n",
            "('Non-random', None, 6)\n",
            "('Non-random', 'Parent', 2)\n",
            "('Random', 'Parent', 111)\n",
            "('Random', 'Teacher', 81)\n",
            "('Random', 'Researcher', 40)\n",
            "('Random', 'Combined - Teacher and Parent', 24)\n",
            "('Random', None, 11)\n",
            "in the extracted table:\n",
            "('Random', 'Parent', 17)\n"
          ]
        }
      ],
      "source": [
        "idkWhatToFind('content/database.db', gt_table, extracted_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Studies_with_missing_data(conn, gt, ext):\n",
        "    '''Find studies present in both tables but with missing (NULL or empty) values in key columns:\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    cursor.execute(f\"\"\"\n",
        "                    SELECT {gt}.Study, {gt}.Allocation AS GT_Allocation, {ext}.Allocation AS EXT_Allocation,\n",
        "                    {gt}.Experimenter AS GT_Experimenter, {ext}.Experimenter AS EXT_Experimenter\n",
        "                    FROM {gt}\n",
        "                    JOIN {ext} ON {gt}.Study = {ext}.Study\n",
        "                    WHERE {ext}.Allocation IS NULL\n",
        "                        OR {ext}.Experimenter IS NULL\n",
        "                        OR {ext}.Allocation = ''\n",
        "                        OR {ext}.Experimenter = ''; \"\"\")\n",
        "    test_table = cursor.fetchall()\n",
        "    if not test_table:\n",
        "        print(\"No studies with missing data found.\")\n",
        "\n",
        "    else : \n",
        "        print(\"Studies with Missing Data : \")\n",
        "        for row in test_table:\n",
        "            print(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No studies with missing data found.\n"
          ]
        }
      ],
      "source": [
        "Studies_with_missing_data('content/database.db', gt_table, extracted_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######## this is not what i wanted to do ########\n",
        "def DistributionOfCathegories(conn, gt, ext, column = 'Allocation', cathegory = ['Random', 'Non-random']):\n",
        "    '''Distribution of Categories in Ground Truth and Extracted Data\n",
        "        Compares the distribution of categories in the ground truth and extracted data.\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    for cat in cathegory:\n",
        "        cursor.execute(f\"\"\"\n",
        "                        SELECT COUNT(*) FROM {gt} GROUP BY {cat};\n",
        "                        \"\"\")\n",
        "        gt_count = cursor.fetchone()[0] \n",
        "        \n",
        "        cursor.execute(f\"\"\"\n",
        "                        SELECT COUNT(*) FROM {ext} GROUP BY {cat};\n",
        "                        \"\"\")\n",
        "        ext_count = cursor.fetchone()[0]\n",
        "        \n",
        "        print(f\"Category '{cat}': Ground Truth Count: {gt_count}, Extracted Count: {ext_count}\")\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def plotDistributionByCathegory(gt_count, ext_count) :\n",
        "    '''bar plot of the distribution of categories in the ground truth and extracted data.'''\n",
        "\n",
        "    ##### place holder for the plot #####\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DistributionOfCathegories('content/database.db', gt_table, extracted_table, 'Allocation')  \n",
        "DistributionOfCathegories('content/database.db', gt_table, extracted_table, 'Experimenter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## To do :\n",
        "- test the other written queries\n",
        "- test with the multiple shots prompting (it's only done with the python code i should've started here)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
